# Text-to-video-generation-model
Damo-vilab Text-to-Videos model leverages a sophisticated multi-stage diffusion architecture to transform textual descriptions into corresponding video sequences. 

Exclusively designed for English input, the model comprises three integral sub-networks:
1. Text feature extraction model
2. Text feature-to-video latent space diffusion model
3. Video latent space to video visual space model
